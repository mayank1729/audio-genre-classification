{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Model.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ElWP1P3JKwx"
      },
      "source": [
        "import requests\n",
        "\n",
        "def download_file_from_google_drive(id, destination):\n",
        "    URL = \"https://docs.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params = { 'id' : id }, stream = True)\n",
        "    token = get_confirm_token(response)\n",
        "\n",
        "    if token:\n",
        "        params = { 'id' : id, 'confirm' : token }\n",
        "        response = session.get(URL, params = params, stream = True)\n",
        "\n",
        "    save_response_content(response, destination)    \n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk: # filter out keep-alive new chunks\n",
        "                f.write(chunk)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1jgy5RfJL6n"
      },
      "source": [
        "download_file_from_google_drive('181Ua_0HhqaWlyCeHD6_hFsPZhGbFKbU8', '/content/prepared.zip')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbhAH2YQJA2N"
      },
      "source": [
        "import tensorflow as tf\n",
        "import sklearn as skl\n",
        "import librosa as lr\n",
        "import numpy as np\n",
        "import logging\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ffnPEUpJA2R"
      },
      "source": [
        "logging.warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "847kKzFpJA2U"
      },
      "source": [
        "### Genre Selection:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qitXVC_OJA2U"
      },
      "source": [
        "genres = {\n",
        "    'blues': 0,\n",
        "    'classical': 1,\n",
        "    'country': 2,\n",
        "    'disco': 3,\n",
        "    'hiphop': 4,\n",
        "    'jazz': 5,\n",
        "    'metal': 6,\n",
        "    'pop': 7,\n",
        "    'reggae': 8,\n",
        "    'rock': 9\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2woMl1kJA2W"
      },
      "source": [
        "### Hyper Parameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8NC8G0TJA2X"
      },
      "source": [
        "hparams = {\n",
        "    'samplerate': 22050,\n",
        "    'seq_length': 256,\n",
        "    'hop_length': 512,\n",
        "    'fft_window': 2048,\n",
        "    'num_classes': len(genres)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJvf5hVRJA2Z"
      },
      "source": [
        "### Extract Features:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BMALACpJA2e"
      },
      "source": [
        "##### Generate Train Dataset if not exist:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "1YnZfW4TJA2f"
      },
      "source": [
        "train_x = np.load('./prepared/train_x.npy', allow_pickle=False)\n",
        "val_x = np.load('./prepared/val_x.npy', allow_pickle=False)\n",
        "test_x = np.load('./prepared/test_x.npy', allow_pickle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtFfGVhHJA2m"
      },
      "source": [
        "### Generate Ground Truth Labels:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8VLJQNHJA2n"
      },
      "source": [
        "train_y = np.zeros(shape=(5 * 70 * hparams['num_classes'], hparams['num_classes']), dtype=float)\n",
        "val_y   = np.zeros(shape=(5 * 20 * hparams['num_classes'], hparams['num_classes']), dtype=float)\n",
        "test_y  = np.zeros(shape=(5 * 10 * hparams['num_classes'], hparams['num_classes']), dtype=float)\n",
        "\n",
        "train_counter = 0\n",
        "val_counter   = 0\n",
        "test_counter  = 0\n",
        "\n",
        "for i in range(5 * 70 * hparams['num_classes']):\n",
        "    train_y[train_counter, :] = tf.keras.utils.to_categorical(train_counter // (5*70), num_classes=hparams['num_classes'])\n",
        "    train_counter += 1\n",
        "\n",
        "for i in range(5 * 20 * hparams['num_classes']):\n",
        "    val_y[val_counter, :] = tf.keras.utils.to_categorical(val_counter // (5*20), num_classes=hparams['num_classes'])\n",
        "    val_counter += 1\n",
        "        \n",
        "for i in range(5 * 10 * hparams['num_classes']):\n",
        "    test_y[test_counter, :] = tf.keras.utils.to_categorical(test_counter // (5*10), num_classes=hparams['num_classes'])\n",
        "    test_counter += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSGtR0LvJA2p"
      },
      "source": [
        "train_x = np.moveaxis(train_x, 1, 2)\n",
        "val_x = np.moveaxis(val_x, 1, 2)\n",
        "test_x = np.moveaxis(test_x, 1, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QM-MHLOmJA2q"
      },
      "source": [
        "class GenreClassifierModel(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.L1 = tf.keras.layers.LSTM(64, return_sequences=True)\n",
        "        self.L2 = tf.keras.layers.LSTM(64, return_sequences=False)\n",
        "        self.L3 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.L4 = tf.keras.layers.Dropout(0.3)\n",
        "        self.L5 = tf.keras.layers.Dense(units=hparams['num_classes'], activation=\"softmax\")\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        self.x = self.L1(inputs)\n",
        "        self.x = self.L2(self.x)\n",
        "        self.x = self.L3(self.x)\n",
        "        self.x = self.L4(self.x)\n",
        "        self.x = self.L5(self.x)\n",
        "        return self.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cam-ruNJA2t"
      },
      "source": [
        "model = GenreClassifierModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ4xFtqZJA2v"
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "MWnlJrKmJA2x",
        "outputId": "2356a865-ea0a-4eb6-c00c-8ae4da4d659c"
      },
      "source": [
        "hist = model.fit(train_x, train_y, epochs=30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 2.2925 - accuracy: 0.1217\n",
            "Epoch 2/30\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 2.1497 - accuracy: 0.2200\n",
            "Epoch 3/30\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 1.9265 - accuracy: 0.3117\n",
            "Epoch 4/30\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 1.7375 - accuracy: 0.3803\n",
            "Epoch 5/30\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 1.5859 - accuracy: 0.4234\n",
            "Epoch 6/30\n",
            "110/110 [==============================] - 3s 32ms/step - loss: 1.4781 - accuracy: 0.4631\n",
            "Epoch 7/30\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 1.3786 - accuracy: 0.4989\n",
            "Epoch 8/30\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 1.2839 - accuracy: 0.5331\n",
            "Epoch 9/30\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 1.1943 - accuracy: 0.5729\n",
            "Epoch 10/30\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 1.1171 - accuracy: 0.5960\n",
            "Epoch 11/30\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 1.0433 - accuracy: 0.6289\n",
            "Epoch 12/30\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.9512 - accuracy: 0.6594\n",
            "Epoch 13/30\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.8915 - accuracy: 0.6831\n",
            "Epoch 14/30\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.8255 - accuracy: 0.7043\n",
            "Epoch 15/30\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.7688 - accuracy: 0.7234\n",
            "Epoch 16/30\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.6678 - accuracy: 0.7731\n",
            "Epoch 17/30\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.6053 - accuracy: 0.7923\n",
            "Epoch 18/30\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.5722 - accuracy: 0.7969\n",
            "Epoch 19/30\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.5303 - accuracy: 0.8191\n",
            "Epoch 20/30\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.4648 - accuracy: 0.8451\n",
            "Epoch 21/30\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.4305 - accuracy: 0.8620\n",
            "Epoch 22/30\n",
            "110/110 [==============================] - 4s 32ms/step - loss: 0.3995 - accuracy: 0.8663\n",
            "Epoch 23/30\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.3745 - accuracy: 0.8769\n",
            "Epoch 24/30\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 0.3551 - accuracy: 0.8823\n",
            "Epoch 25/30\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.3014 - accuracy: 0.9049\n",
            "Epoch 26/30\n",
            "110/110 [==============================] - 3s 29ms/step - loss: 0.3095 - accuracy: 0.8980\n",
            "Epoch 27/30\n",
            "110/110 [==============================] - 3s 31ms/step - loss: 0.2651 - accuracy: 0.9154\n",
            "Epoch 28/30\n",
            "110/110 [==============================] - 3s 30ms/step - loss: 0.2694 - accuracy: 0.9126\n",
            "Epoch 29/30\n",
            "110/110 [==============================] - 4s 34ms/step - loss: 0.2200 - accuracy: 0.9289\n",
            "Epoch 30/30\n",
            "110/110 [==============================] - 4s 33ms/step - loss: 0.2227 - accuracy: 0.9317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSVVeBkKJA20",
        "outputId": "969822af-1fc9-48d3-f21c-7282a6ab87f8"
      },
      "source": [
        "model.evaluate(val_x, val_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 1s 17ms/step - loss: 3.9246 - accuracy: 0.3670\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3.924561023712158, 0.367000013589859]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "X0PG7WbfJA22",
        "outputId": "d199ec5e-24c3-4afb-b3b9-a0b01d2ea541"
      },
      "source": [
        "gno = 0\n",
        "\n",
        "g = list(genres.keys())[gno]\n",
        "print('Actual Genre', g, gno)\n",
        "\n",
        "for i in range(hparams['num_classes']):\n",
        "\n",
        "    m = hparams['seq_length']\n",
        "    \n",
        "    example = extract_features('./dataset/{}/{}.000'.format(g, g) + str(90+i) + '.wav', hparams)\n",
        "    \n",
        "    segment_1 = np.moveaxis(example, 0, 1)[0*m:1*m, :].reshape(1, m, 40)\n",
        "    segment_2 = np.moveaxis(example, 0, 1)[1*m:2*m, :].reshape(1, m, 40)\n",
        "    segment_3 = np.moveaxis(example, 0, 1)[2*m:3*m, :].reshape(1, m, 40)\n",
        "    segment_4 = np.moveaxis(example, 0, 1)[3*m:4*m, :].reshape(1, m, 40)\n",
        "    segment_5 = np.moveaxis(example, 0, 1)[4*m:5*m, :].reshape(1, m, 40)\n",
        "    \n",
        "    print('===============================================')\n",
        "    print('Segment-0:', np.argmax(model.predict(segment_1)))\n",
        "    print('Segment-1:', np.argmax(model.predict(segment_2)))\n",
        "    print('Segment-2:', np.argmax(model.predict(segment_3)))\n",
        "    print('Segment-3:', np.argmax(model.predict(segment_4)))\n",
        "    print('Segment-4:', np.argmax(model.predict(segment_5)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Actual Genre blues 0\n",
            "===============================================\n",
            "Segment-0: 0\n",
            "Segment-1: 0\n",
            "Segment-2: 9\n",
            "Segment-3: 9\n",
            "Segment-4: 0\n",
            "===============================================\n",
            "Segment-0: 8\n",
            "Segment-1: 2\n",
            "Segment-2: 0\n",
            "Segment-3: 8\n",
            "Segment-4: 2\n",
            "===============================================\n",
            "Segment-0: 0\n",
            "Segment-1: 0\n",
            "Segment-2: 5\n",
            "Segment-3: 0\n",
            "Segment-4: 0\n",
            "===============================================\n",
            "Segment-0: 5\n",
            "Segment-1: 1\n",
            "Segment-2: 0\n",
            "Segment-3: 5\n",
            "Segment-4: 0\n",
            "===============================================\n",
            "Segment-0: 9\n",
            "Segment-1: 0\n",
            "Segment-2: 8\n",
            "Segment-3: 4\n",
            "Segment-4: 0\n",
            "===============================================\n",
            "Segment-0: 5\n",
            "Segment-1: 3\n",
            "Segment-2: 0\n",
            "Segment-3: 2\n",
            "Segment-4: 2\n",
            "===============================================\n",
            "Segment-0: 1\n",
            "Segment-1: 1\n",
            "Segment-2: 2\n",
            "Segment-3: 5\n",
            "Segment-4: 2\n",
            "===============================================\n",
            "Segment-0: 8\n",
            "Segment-1: 8\n",
            "Segment-2: 8\n",
            "Segment-3: 9\n",
            "Segment-4: 9\n",
            "===============================================\n",
            "Segment-0: 6\n",
            "Segment-1: 0\n",
            "Segment-2: 9\n",
            "Segment-3: 0\n",
            "Segment-4: 9\n",
            "===============================================\n",
            "Segment-0: 9\n",
            "Segment-1: 0\n",
            "Segment-2: 8\n",
            "Segment-3: 2\n",
            "Segment-4: 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6Zq7_uqJA24"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}